{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NA values\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "df.select([count(when(isnan(c), c)).alias(c) for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer()\\\n",
    "                 .setInputCol (\"request_id\")\\\n",
    "                 .setOutputCol (\"request_id_index\")\n",
    "\n",
    "trans_request = stringIndexer.fit(df_click)\n",
    "trans_request_df=trans_request.transform(df_click)\n",
    "trans_request_df.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler()\\\n",
    "         .setInputCols ([\"Age_encoded\",\"Pregnancies\",\"Glucose\",\n",
    "                         \"BloodPressure\",\"SkinThickness\",\\\n",
    "                         \"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\"])\\\n",
    "         .setOutputCol (\"vectorized_features\")\n",
    "        \n",
    "\n",
    "assembler_df=assembler.transform(encoder_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\\\n",
    "         .setInputCol (\"vectorized_features\")\\\n",
    "         .setOutputCol (\"features\")\n",
    "        \n",
    "scaler_model=scaler.fit(label_indexer_df)\n",
    "scaler_df=scaler_model.transform(label_indexer_df)\n",
    "scalar_df.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=5)\n",
    "lrModel = lr.fit(train)\n",
    "predictions = lrModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoderEstimator()\\\n",
    "         .setInputCols ([\"Age_udfIndex\"])\\\n",
    "         .setOutputCols ([\"Age_encoded\"])\n",
    "\n",
    "encoder_model=encoder.fit(Age_udfIndex_df)\n",
    "encoder_df=encoder_model.transform(Age_udfIndex_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
